# ğŸ§  MindFlow

MindFlow æ˜¯ä¸€æ¬¾ç¦»çº¿å¯ç”¨çš„ Web åº”ç”¨ï¼Œç”¨ç»“æ„åŒ–è„‘å›¾çš„æ–¹å¼ä¸å¤§æ¨¡å‹å¯¹è¯ã€‚æ¯ä¸€æ¬¡æé—®ä¸å›ç­”éƒ½ä¼šè½åœ°æˆèŠ‚ç‚¹ï¼Œå¸®åŠ©ä½ æ²‰æ·€æ€è€ƒè¿‡ç¨‹ã€ç»„ç»‡çŸ¥è¯†ï¼Œå¹¶éšæ—¶å¯¼å‡ºå¤‡ä»½ã€‚

---

## åŠŸèƒ½ç‰¹æ€§

- ç”»å¸ƒèŠ‚ç‚¹ï¼šæ‹–æ‹½ã€å¢åˆ ã€å±‚çº§è°ƒæ•´ä¸è‡ªåŠ¨å¸ƒå±€ï¼Œé—®é¢˜å’Œå›ç­”ä¸€ç›®äº†ç„¶
- AI äº’è”ï¼šå†…ç½® Echo / HTTP / Docker Model Runner / OpenAI å››ç±»å®¢æˆ·ç«¯ï¼Œå¯æŒ‰éœ€åˆ‡æ¢
- èŠ‚ç‚¹æ±‡æ€»ï¼šä¸€é”®æ”¶é›†å½“å‰èŠ‚ç‚¹åŠå­èŠ‚ç‚¹çš„é—®ç­”ï¼Œå‹ç¼©æ€»ç»“åå†™å›å½“å‰èŠ‚ç‚¹
- ç¦»çº¿æŒä¹…åŒ–ï¼šPinia + IndexedDB è‡ªåŠ¨ä¿å­˜ï¼Œæ–­ç½‘ä¹Ÿèƒ½ç»§ç»­ç¼–è¾‘
- å†å²ç•™å­˜ï¼šåç«¯ JSON æ—¥å¿—è®°å½•æ‰€æœ‰é—®ç­”ï¼Œæ–¹ä¾¿å®¡è®¡ä¸æ¢å¤
- å¿«é€Ÿå¯¼å‡ºï¼šä¸€é”®å¯¼å‡ºå½“å‰è„‘å›¾ JSONï¼Œä¾¿äºè¿ç§»æˆ–å¤‡ä»½

---

## æŠ€æœ¯ & ç›®å½•

| æ¨¡å— | æŠ€æœ¯æ ˆ |
| --- | --- |
| å‰ç«¯ | Vue 3 + Vite Â· Pinia Â· Konva.js Â· LocalForage |
| åç«¯ | FastAPI Â· httpx Â· Pydantic Settings |

```
mindflow/
â”œâ”€â”€ frontend/        # Vue åº”ç”¨
â”œâ”€â”€ backend/         # FastAPI æœåŠ¡
â”œâ”€â”€ start.sh         # ä¸€é”®å¯åŠ¨è„šæœ¬ï¼ˆå¯é€‰ï¼‰
â””â”€â”€ stop.sh
```

---

## æ¶æ„å¿«ç…§

```
[Vue 3 Canvas UI] --Axios--> [/ask Â· FastAPI] --AIClient-->
  (Pinia State + IndexedDB)      (echo/http/docker/openai) --> æ¨¡å‹
```

---

## å¿«é€Ÿå¼€å§‹

> å¼€å§‹å‰è¯·å®‰è£… Node.js â‰¥ 18 ä¸ Python â‰¥ 3.10ã€‚

### 1. é¦–æ¬¡å®‰è£…ä¾èµ–ï¼ˆåªéœ€æ‰§è¡Œä¸€æ¬¡ï¼‰

```bash
# å‰ç«¯ä¾èµ–
cd frontend
npm install

# åç«¯ä¾èµ–
cd ../backend
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### 2. å¯åŠ¨ / åœæ­¢æœåŠ¡

å®Œæˆä¾èµ–å®‰è£…åï¼Œå¯åœ¨ä»“åº“æ ¹ç›®å½•ä½¿ç”¨è„šæœ¬ä¸€é”®èµ·åœï¼š

```bash
./start.sh   # åŒæ—¶å¯åŠ¨å‰åç«¯ï¼ˆ5173 / 8000ï¼‰
./stop.sh    # å®‰å…¨å…³é—­ï¼Œå¹¶æ¸…ç† PID / æ—¥å¿—æ ‡è®°
```

å¦‚æœéœ€è¦å•ç‹¬è¿è¡Œï¼Œå¯ä¾æ—§è¿›å…¥å„å­ç›®å½•æ‰§è¡Œ `npm run dev` æˆ– `uvicorn main:app --reload`ã€‚é¡¹ç›®é»˜è®¤æŠŠ `/api` ä»£ç†åˆ° `http://localhost:8000`ï¼Œåç«¯ä¼šåœ¨ `backend/data/history.json` ä¸­è‡ªåŠ¨å†™å…¥é—®ç­”æ—¥å¿—ã€‚

---

## æ¨¡å‹æ¥å…¥

| provider | é€‚ç”¨åœºæ™¯ | å…³é”®å­—æ®µ |
| --- | --- | --- |
| `echo` | æœ¬åœ°æ¼”ç¤ºï¼Œæ— çœŸå®æ¨ç† | æ—  |
| `http` | è‡ªå»º HTTP æœåŠ¡ / Ollama / LM Studio | `base_url`ï¼Œ`headers`ï¼ˆå¯é€‰ï¼‰ |
| `docker` | [Docker Model Runner](https://github.com/modelscope/modelscope/blob/master/modelscope/tools/model_runner/README.md) | `base_url`ï¼ˆæŒ‡å‘ `/engines/{engine}/v1/chat/completions`ï¼‰ï¼Œ`model`ï¼Œ`timeout`ï¼ˆå¯é€‰ï¼Œå•ä½ç§’ï¼‰ |
| `openai` | OpenAI æˆ–å…¼å®¹ APIï¼ˆAzureã€OpenRouter ç­‰ï¼‰ | `api_key`ï¼Œ`model`ï¼Œ`base_url`ï¼ˆå¯é€‰ï¼‰ï¼Œ`timeout`ï¼ˆå¯é€‰ï¼‰ |

ç¤ºä¾‹é…ç½®ï¼ˆç›´æ¥ç¼–è¾‘ `backend/config.toml`ï¼Œæˆ–ä½¿ç”¨ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰ï¼š

**Echoï¼ˆå†…ç½®å›å£°ï¼‰**

```toml
[ai]
provider = "echo"
```

**HTTPï¼ˆOllama / LM Studio ç­‰è‡ªå»ºæ¥å£ï¼‰**

```toml
[ai]
provider = "http"
base_url = "http://localhost:11434/api/generate"
timeout = 60

[ai.headers]
Authorization = "Bearer custom-token"
```

**Docker Model Runner**

```toml
[ai]
provider = "docker"
base_url = "http://localhost:12434/engines/llama.cpp/v1/chat/completions"
model = "ai/gemma3"
timeout = 60  # å•ä½ç§’ï¼Œå¯æŒ‰æ¨¡å‹åŠ è½½é€Ÿåº¦è‡ªè¡Œè°ƒæ•´
```

å¯åŠ¨ Docker Model Runner åï¼Œå¯å…ˆä½¿ç”¨ï¼š

```bash
curl http://localhost:12434/engines/llama.cpp/v1/chat/completions \
  -X POST \
  -H "Content-Type: application/json" \
  -d '{"model":"ai/gemma3","messages":[{"role":"user","content":"ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}]}'
```

è‹¥éœ€è¦ä¸´æ—¶è¦†ç›–é…ç½®ï¼Œå¯åœ¨å¯åŠ¨ FastAPI å‰å¯¼å‡ºç¯å¢ƒå˜é‡ï¼š

```bash
export MINDFLOW_PROVIDER=docker
export MINDFLOW_BASE_URL=http://localhost:12434/engines/llama.cpp/v1/chat/completions
export MINDFLOW_MODEL=ai/gemma3
```

**OpenAI / å…¼å®¹æœåŠ¡ï¼ˆé»˜è®¤èµ° `/v1/responses`ï¼Œå¦‚éœ€æ—§ç‰ˆå¯æŠŠ base_url æ”¹ä¸º `/v1/chat/completions`ï¼‰**

```toml
[ai]
provider = "openai"
api_key = "sk-***"
model = "gpt-5-nano"
base_url = "https://api.openai.com/v1/responses"  # å¯é€‰
timeout = 60
```

OpenAI Python å®¢æˆ·ç«¯ç¤ºä¾‹ï¼ˆä¸åå°å®ç°ä¿æŒä¸€è‡´ï¼‰ï¼š

```python
from openai import OpenAI

client = OpenAI()
response = client.responses.create(
    model="gpt-5-nano",
    input="Write a one-sentence bedtime story about a unicorn."
)

print(response.output_text)
```

---

## å¼€å‘æç¤º

- `backend/config.toml` æ˜¯å”¯ä¸€çš„é»˜è®¤é…ç½®æ–‡ä»¶ï¼Œå¯ç›´æ¥ä¿®æ”¹æˆ–ä½¿ç”¨ç¯å¢ƒå˜é‡è¦†ç›–
- `frontend/src/utils/db.ts` è´Ÿè´£ IndexedDB è¯»å†™ï¼Œå¦‚éœ€æ›´æ¢æŒä¹…åŒ–ç­–ç•¥å¯ä»æ­¤å¤„å…¥æ‰‹
- `backend/services/ai_client.py` ç»Ÿä¸€å¤„ç†æ¨¡å‹è¯·æ±‚ä¸é—®ç­”æ—¥å¿—ï¼Œæ–°å¢ provider ä¹Ÿåœ¨æ­¤æ‰©å±•
- `backend/routers/summary.py` æ±‡æ€»èŠ‚ç‚¹å†…å®¹å¹¶è°ƒç”¨ AI å‹ç¼©ï¼Œå¯ç”¨äºè‡ªå®šä¹‰æ‘˜è¦ç­–ç•¥
- æäº¤ PR å‰å»ºè®®è¿è¡Œ `npm run build`ï¼ˆå‰ç«¯ï¼‰ä¸ `pytest` / `ruff`ï¼ˆè‹¥å·²é…ç½®ï¼‰ç¡®ä¿è´¨é‡

---

## è·¯çº¿å›¾

- [ ] èŠ‚ç‚¹å¤šé€‰ä¸æ‰¹é‡æ“ä½œ
- [ ] ä¼šè¯ä¸Šä¸‹æ–‡æ¨¡å¼
- [ ] PWA æ‰“åŒ…ä¸æ¡Œé¢å®‰è£…
- [ ] AI ç”Ÿæˆå­èŠ‚ç‚¹æ¨è

æ¬¢è¿ Issue / PRï¼Œä¸€èµ·æŠŠ MindFlow æ‰“ç£¨æˆæ›´å¥½ç”¨çš„ AI ç¬”è®°å·¥å…·ã€‚ğŸ‰
