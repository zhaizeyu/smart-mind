# MindFlow

> ç”¨æ€ç»´å¯¼å›¾å’Œæœ¬åœ°/äº‘ç«¯å¤§æ¨¡å‹å¯¹è¯ï¼Œéšæ‰‹è®°å½•æ¯æ¬¡é—®ç­”ã€‚

## åŠŸèƒ½äº®ç‚¹

- æ‹–æ‹½å¼è„‘å›¾ï¼šèŠ‚ç‚¹å¯è‡ªç”±ç§»åŠ¨ã€é‡æ’å±‚çº§ï¼Œçˆ¶å­å…³ç³»éšæ‹–æ”¾å³æ—¶æ›´æ–°
- AI åŒå‘åä½œï¼šå‘æ¨¡å‹æé—®ã€æ±‡æ€»èŠ‚ç‚¹ç­”æ¡ˆã€è‡ªåŠ¨ç”Ÿæˆ 2 ä¸ªå‘æ•£å­é—®é¢˜
- åŒé‡æŒä¹…åŒ–ï¼šå‰ç«¯æ•°æ®å­˜å…¥ IndexedDBï¼Œåç«¯åŒæ­¥ `backend/data/mindmap.json`
- ä¸€é”®è„šæœ¬ï¼š`start.sh` / `stop.sh` åŒæ—¶ç®¡ç†å‰åç«¯
- å¯æ§å›ç­”é£æ ¼ï¼š`answer_style` æç¤ºè¯å½±å“æ‰€æœ‰æ¨¡å‹å›å¤ï¼Œé»˜è®¤â€œç®€è¦å›ç­”â€

## æŠ€æœ¯æ ˆ

| æ¨¡å— | è¯´æ˜ |
| --- | --- |
| å‰ç«¯ | Vue 3 + Vite Â· Pinia Â· Konva.js Â· LocalForage |
| åç«¯ | FastAPI Â· httpx Â· Pydantic Settings |

ç›®å½•ç»“æ„ï¼š

```
mindflow/
â”œâ”€â”€ frontend/    # Vue åº”ç”¨
â”œâ”€â”€ backend/     # FastAPI æœåŠ¡
â”œâ”€â”€ start.sh     # ä¸€é”®å¯åŠ¨
â””â”€â”€ stop.sh
```

## å¿«é€Ÿå¼€å§‹

```bash
# å®‰è£…ä¾èµ–
cd frontend && npm install
cd ../backend && python3 -m venv .venv && source .venv/bin/activate && pip install -r requirements.txt

# å¯åŠ¨ / åœæ­¢ï¼ˆæ ¹ç›®å½•æ‰§è¡Œï¼‰
./start.sh
./stop.sh
```

å¼€å‘æ—¶ä¹Ÿå¯ä»¥åˆ†åˆ«è¿è¡Œ `npm run dev` å’Œ `uvicorn main:app --reload`ï¼Œå‰ç«¯å·²é€šè¿‡ Vite ä»£ç†æŠŠ `/api` æŒ‡å‘ `http://localhost:8000`ã€‚

## é…ç½®å¤§æ¨¡å‹

`backend/config.toml` æ˜¯å”¯ä¸€çš„é…ç½®æ–‡ä»¶ï¼Œä¹Ÿå¯ç”¨ `MINDFLOW_` ç¯å¢ƒå˜é‡è¦†ç›–ã€‚æ‰€æœ‰ provider éƒ½æ”¯æŒ `answer_style`ï¼ˆæç¤ºè¯ï¼‰å½±å“å›å¤é£æ ¼ã€‚

| provider | é€‚ç”¨åœºæ™¯ | å…³é”®å­—æ®µ |
| --- | --- | --- |
| `echo` | æœ¬åœ°æ¼”ç¤ºï¼Œæ— çœŸå®æ¨ç† | `answer_style`ï¼ˆå¯é€‰ï¼‰ |
| `http` | è‡ªå»º HTTP æ¥å£ / Ollama / LM Studio | `base_url`ã€`headers`ï¼ˆå¯é€‰ï¼‰ã€`timeout`ã€`answer_style` |
| `docker` | ModelScope Docker Model Runner | `base_url`ã€`model`ã€`timeout`ã€`answer_style` |
| `openai` | OpenAI / Azure / OpenRouter ç­‰ | `api_key`ã€`model`ã€`base_url`ï¼ˆå¯é€‰ï¼‰ã€`timeout`ã€`answer_style` |

ç¤ºä¾‹ï¼ˆDocker æ¨¡å¼ï¼‰ï¼š

```toml
[ai]
provider = "docker"
base_url = "http://localhost:12434/engines/llama.cpp/v1/chat/completions"
model = "ai/gemma3"
timeout = 60
answer_style = "ä½ æ˜¯ä¸€åç®€æ˜æ‰¼è¦çš„åŠ©ç†ï¼Œè¯·ç”¨ 2-3 å¥è¯ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
```

è‹¥è¦ä¸´æ—¶è¦†ç›–é…ç½®ï¼š

```bash
export MINDFLOW_PROVIDER=docker
export MINDFLOW_BASE_URL=http://localhost:12434/engines/llama.cpp/v1/chat/completions
export MINDFLOW_MODEL=ai/gemma3
export MINDFLOW_ANSWER_STYLE="æ›´å…·è±¡ã€æœ‰ä¾‹å­çš„å›ç­”"
```

OpenAI Python SDK å¯¹åº”è°ƒç”¨ï¼š

```python
from openai import OpenAI
client = OpenAI()
response = client.responses.create(
    model="gpt-5-nano",
    input="Write a one-sentence bedtime story about a unicorn."
)
print(response.output_text)
```

## å¼€å‘æç¤º

- `frontend/src/stores/useMindStore.ts` è´Ÿè´£æ•´ä¸ªè„‘å›¾æ•°æ®ç»“æ„ï¼Œæ–°å¢è¡Œä¸ºè¯·åœ¨æ­¤ç»Ÿä¸€ç®¡ç†
- `frontend/src/components/MindMapCanvas.vue` å¤„ç†æ‹–æ‹½/è¿çº¿é€»è¾‘
- `backend/services/ai_client.py` æŠ½è±¡äº†æ‰€æœ‰ provider çš„è°ƒç”¨ä¸å›ç­”é£æ ¼æç¤º
- `backend/routers/summary.py` / `backend/routers/generate.py` åˆ†åˆ«æä¾›â€œèŠ‚ç‚¹æ±‡æ€»â€å’Œâ€œAI ç”Ÿæˆå­èŠ‚ç‚¹â€æ¥å£
- `backend/routers/mindmap.py` è´Ÿè´£è„‘å›¾çš„æœåŠ¡ç«¯å­˜å‚¨ï¼Œé˜²æ­¢æµè§ˆå™¨ç¼“å­˜æ¸…ç©ºåæ•°æ®ä¸¢å¤±
- æäº¤ PR å‰å»ºè®®è¿è¡Œ `npm run build`ï¼ˆå‰ç«¯ï¼‰ä¸é€‚ç”¨çš„ Python æµ‹è¯• / Lint

æ¬¢è¿ Issue / PRï¼Œè®© MindFlow æˆä¸ºæ›´å¥½ç”¨çš„è„‘å›¾å¼ AI ç¬”è®°å·¥å…·ã€‚ğŸ‰
